{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL2XpsFrt0As"
   },
   "source": [
    "## CSCI S-89 Introduction to Deep Learning\n",
    "Harvard Summer School 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdHImPpGs2bS"
   },
   "source": [
    "# Final Project:\n",
    "# *Face Recognition with Deep Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNYMZbIiZRd1"
   },
   "source": [
    "The goal of this project is to detect human faces in images and recognize who the faces belong to from a predefined group of people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8lLLdajo-ZW"
   },
   "source": [
    "# Part III: **Prepare and Preprocess Input Data for the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXuLRRLR02Gu"
   },
   "source": [
    "Next, we will turn the input face images into the format that the model expects to start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt60r5Pw4hby"
   },
   "source": [
    "We will create 2 new folders, one for training and one for validation, and we will split our input data into them.<br>\n",
    "We will use 80% of the data for training and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLZDSAqf5Qm3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the original path to the images.\n",
    "original_dataset = os.path.join(project_path, 'face_recognition_dataset', 'peoples_faces', 'peoples_faces')\n",
    "\n",
    "# Path where we will put the training and the validation folders.\n",
    "target_folder = os.path.join(project_path, 'face_recognition_dataset', 'peoples_faces')\n",
    "\n",
    "# Create the training folder.\n",
    "train_dir = os.path.join(target_folder, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# Create the validation folder.\n",
    "val_dir = os.path.join(target_folder, 'validation')\n",
    "os.mkdir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS5Nvg21FIRP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "# For every person in the original dataset...\n",
    "for person in os.listdir(original_dataset):\n",
    "  # Take the person's folder.\n",
    "  persons_folder = os.path.join(original_dataset, person)\n",
    "\n",
    "  # Shuffle the images in the folder\n",
    "  # to make everything fairer.\n",
    "  images = os.listdir(persons_folder)\n",
    "  random.shuffle(images)\n",
    "\n",
    "  # Split the images into training and validation subsets.\n",
    "  split_point = int(len(images) * 0.8)\n",
    "  train_images = images[:split_point]\n",
    "  validation_images = images[split_point:]\n",
    "\n",
    "  # Create new folders for the person\n",
    "  # in the training and the validation folders.\n",
    "  train_person_dir = os.path.join(train_dir, person)\n",
    "  os.mkdir(train_person_dir)\n",
    "\n",
    "  val_person_dir = os.path.join(val_dir, person)\n",
    "  os.mkdir(val_person_dir)\n",
    "\n",
    "  # Copy training images to train folder.\n",
    "  for img in train_images:\n",
    "    current_image_path = os.path.join(persons_folder, img)\n",
    "    target_path = os.path.join(train_person_dir, img)\n",
    "    shutil.copy(current_image_path, target_path)\n",
    "\n",
    "  # Copy validation images to validation folder.\n",
    "  for img in validation_images:\n",
    "    current_image_path = os.path.join(persons_folder, img)\n",
    "    target_path = os.path.join(val_person_dir, img)\n",
    "    shutil.copy(current_image_path, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lglKResVQFvV"
   },
   "source": [
    "For the following preprocessing steps I used the online tensorflow documentation (https://www.tensorflow.org/tutorials/images/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a3D_aQvuDhP"
   },
   "source": [
    "We will format the input data accordingly for the model:\n",
    "1.   We will define that every person in the dataset is a class.\n",
    "2.   We will give labels to the images (the name of the person, a.k.a. the name of the folder).\n",
    "3.   We will load the images in batches (32).\n",
    "4.   We will make sure all images are 224x224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nCnh9bJ4j_T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "target_folder = os.path.join(project_path, 'face_recognition_dataset', 'peoples_faces')\n",
    "train_dir = os.path.join(target_folder, 'train')\n",
    "val_dir = os.path.join(target_folder, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q78ZHORh2Znn",
    "outputId": "fa729de5-90b9-477c-91a4-36111d2d72cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1280 files belonging to 20 classes.\n",
      "Found 320 files belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Format images for training.\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical', # one-hot encoded labels for Categorical Crossentropy\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Format images for validation.\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-QnbBxs6gws",
    "outputId": "7df9e6ba-e9e1-4646-9ce3-f4ed5d224989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "  Image Shape: (32, 224, 224, 3)\n",
      "  Label Shape: (32, 20)\n",
      "\n",
      "Validation Dataset:\n",
      "  Image Shape: (32, 224, 224, 3)\n",
      "  Label Shape: (32, 20)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds:\n",
    "  print('Train Dataset:')\n",
    "  print(f'  Image Shape: {images.shape}')\n",
    "  print(f'  Label Shape: {labels.shape}')\n",
    "  print()\n",
    "  break\n",
    "\n",
    "for images, labels in val_ds:\n",
    "  print('Validation Dataset:')\n",
    "  print(f'  Image Shape: {images.shape}')\n",
    "  print(f'  Label Shape: {labels.shape}')\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UugnVLfV7zjD"
   },
   "source": [
    "And of course we will **scale the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaCuR1JM8_GP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "# Perform pixel normalization.\n",
    "train_ds_scaled = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "val_ds_scaled = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzSIMk-3IZku"
   },
   "source": [
    "And we do **data augmentation** to prevent overfitting and improve generalization (only to the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLRAgyZIJD1X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomTranslation(0.2, 0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "train_ds_scaled_aug = train_ds_scaled.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXTdgqgdY5Zh"
   },
   "source": [
    "And now we are ready to build, compile, and train our face recognition model."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
